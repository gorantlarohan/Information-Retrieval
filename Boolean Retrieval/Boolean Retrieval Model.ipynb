{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import argparse\n",
    "import os\n",
    "import sys,re\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_path='/Users/rohan/Desktop/6th sem/Information Retrieval/other/Docs/'\n",
    "data_path='/Users/rohan/Desktop/6th sem/Information Retrieval/other/Data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"Preprocessing Text\"\n",
    "def preprocess_text(text):\n",
    "    processed_text = text.lower()\n",
    "    processed_text = processed_text.replace(\"’\", \"'\")\n",
    "    processed_text = processed_text.replace(\"“\", '\"')\n",
    "    processed_text = processed_text.replace(\"”\", '\"')\n",
    "    non_words = re.compile(r\"[^A-Za-z']+\")\n",
    "    processed_text = re.sub(non_words, ' ', processed_text)\n",
    "\n",
    "    return processed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text_from_file(filename):\n",
    "    with open(filename, encoding='cp1252', mode='r') as f:\n",
    "        text = f.read()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_words_from_text(text):\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    processed_text = preprocess_text(text)\n",
    "    words = {w for w in processed_text.split() if w not in stop_words}#Removing Stop Words\n",
    "    wordset=[]\n",
    "    wordset1=[]\n",
    "    #Stemming\n",
    "    porter = nltk.PorterStemmer()\n",
    "    for word1 in words:\n",
    "        words=porter.stem(word1)\n",
    "        wordset.append(words)\n",
    "    #Lemmatizing\n",
    "    wnl = nltk.WordNetLemmatizer()\n",
    "    for word2 in wordset:\n",
    "        words1=wnl.lemmatize(word2)\n",
    "        wordset1.append(words1)    \n",
    "    \n",
    "    return wordset1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_inverted_index(docs_path):\n",
    "    inverted_index = {}\n",
    "\n",
    "    for doc_file in os.listdir(docs_path):\n",
    "        filename = os.path.join(docs_path, doc_file)\n",
    "        text = get_text_from_file(filename)\n",
    "        words = get_words_from_text(text)\n",
    "\n",
    "        for word in words:\n",
    "            if inverted_index.get(word, None) is None:\n",
    "                inverted_index[word] = {filename}\n",
    "            else:\n",
    "                inverted_index[word].add(filename)\n",
    "    return inverted_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def index(docs_path, data_path):\n",
    "    inverted_index = build_inverted_index(docs_path)\n",
    "    dic_file = os.path.join(data_path, 'dictionary.txt')\n",
    "    inverted_index_file = os.path.join(data_path, 'inverted_index.pickle')\n",
    "\n",
    "    with open(dic_file, mode='w') as f:\n",
    "        for word in inverted_index.keys():\n",
    "            f.write(word + '\\n')\n",
    "\n",
    "    with open(inverted_index_file, mode='wb') as f:\n",
    "        pickle.dump(inverted_index, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "index(docs_path, data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_pickle('/Users/rohan/Desktop/6th sem/Information Retrieval/other/Data/inverted_index.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.DataFrame.from_dict(df, orient=\"index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.to_csv('/Users/rohan/Desktop/6th sem/Information Retrieval/other/Data/inverted_index.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  \"Querying AND , OR , NOT\"\n",
    "inverted_index_file = os.path.join(os.getcwd(), 'Data', 'inverted_index.pickle')\n",
    "\n",
    "with open(inverted_index_file, mode='rb') as f:\n",
    "    inverted_index = pickle.load(f)\n",
    "\n",
    "dictionary = inverted_index.keys()\n",
    "\n",
    "non_words = re.compile(r\"[^A-Za-z'?]+\")\n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Enter your query with space in between and also boolean operation \"AND,OR,NOT\"\n",
    "query=\"trader\"\n",
    "operation=\"not\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove all stopwords and words which is not in dictionary\n",
    "query = query.lower()\n",
    "operation=operation.lower()\n",
    "query = re.sub(non_words, ' ', query)\n",
    "words = {word for word in query.split() \n",
    "         if word not in stop_words and word in dictionary}\n",
    "\n",
    "list_docs=set()\n",
    "for doc_file in os.listdir(docs_path):\n",
    "    filename = os.path.join(docs_path, doc_file)\n",
    "    list_docs.add(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_list=query.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'/Users/rohan/Desktop/6th sem/Information Retrieval/other/Docs/Rout of hossars.txt', '/Users/rohan/Desktop/6th sem/Information Retrieval/other/Docs/yoked with an unbeliever.txt', '/Users/rohan/Desktop/6th sem/Information Retrieval/other/Docs/False Dawn.txt', '/Users/rohan/Desktop/6th sem/Information Retrieval/other/Docs/Wressley of the foreign office.txt', '/Users/rohan/Desktop/6th sem/Information Retrieval/other/Docs/.DS_Store', '/Users/rohan/Desktop/6th sem/Information Retrieval/other/Docs/Consequences.txt', '/Users/rohan/Desktop/6th sem/Information Retrieval/other/Docs/Cupids arrow.txt', '/Users/rohan/Desktop/6th sem/Information Retrieval/other/Docs/on the strength of a likeness.txt', '/Users/rohan/Desktop/6th sem/Information Retrieval/other/Docs/pig.txt', '/Users/rohan/Desktop/6th sem/Information Retrieval/other/Docs/Miss Yougals sais.txt', '/Users/rohan/Desktop/6th sem/Information Retrieval/other/Docs/In the pride of his youth.txt', '/Users/rohan/Desktop/6th sem/Information Retrieval/other/Docs/Bisara of pooree.txt', '/Users/rohan/Desktop/6th sem/Information Retrieval/other/Docs/Three And—An Extra.txt', '/Users/rohan/Desktop/6th sem/Information Retrieval/other/Docs/The other Man.txt', '/Users/rohan/Desktop/6th sem/Information Retrieval/other/Docs/His chance in life.txt', '/Users/rohan/Desktop/6th sem/Information Retrieval/other/Docs/Venus Annodomini.txt', '/Users/rohan/Desktop/6th sem/Information Retrieval/other/Docs/Lispeth.txt', '/Users/rohan/Desktop/6th sem/Information Retrieval/other/Docs/The brochkorst divorce case.txt', '/Users/rohan/Desktop/6th sem/Information Retrieval/other/Docs/The rescue of the pluffles.txt', '/Users/rohan/Desktop/6th sem/Information Retrieval/other/Docs/Watches of the night.txt', '/Users/rohan/Desktop/6th sem/Information Retrieval/other/Docs/The gate of a hundred sorrows.txt', '/Users/rohan/Desktop/6th sem/Information Retrieval/other/Docs/Thrown Away.txt', '/Users/rohan/Desktop/6th sem/Information Retrieval/other/Docs/Story of Muhammed din.txt', '/Users/rohan/Desktop/6th sem/Information Retrieval/other/Docs/By word of mouth.txt'}\n"
     ]
    }
   ],
   "source": [
    "if operation==\"and\":\n",
    "    result = inverted_index.get(words_list[0])\n",
    "    result1=inverted_index.get(words_list[1])\n",
    "    output=result.intersection(result1)\n",
    "elif operation==\"or\":\n",
    "    result = inverted_index.get(words_list[0])\n",
    "    result1=inverted_index.get(words_list[1])\n",
    "    output=result.union(result1)\n",
    "elif operation==\"not\":\n",
    "    result = inverted_index.get(words_list[0])\n",
    "    output=list_docs.difference(result)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result1=None\n",
    "result=None\n",
    "for word in words:\n",
    "    if result is None:\n",
    "        result = inverted_index.get(word)\n",
    "    elif operation==\"and\":\n",
    "        print('and')\n",
    "        result.intersection_update(inverted_index.get(word))\n",
    "    elif operation==\"or\":\n",
    "        print('or')\n",
    "        result.union(inverted_index.get(word))\n",
    "    elif operation==\"not\":\n",
    "        b=inverted_index.get(word)\n",
    "        result1=list_docs.difference(b)\n",
    "        print(result1)\n",
    "    else:\n",
    "        print(result)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "list_a=set()\n",
    "for word in words:\n",
    "    b=inverted_index.get(word)\n",
    "    #list_a.add(b)\n",
    "#print(type(list_a))\n",
    "#list_b={*list_a}\n",
    "result1=list_docs.difference(b)\n",
    "print(result1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result=None\n",
    "result = inverted_index.get('lie')\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result1=None\n",
    "result = inverted_index.get('lie')\n",
    "result1=inverted_index.get('unhappi')\n",
    "print(result1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.union(result1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_docs.difference(result1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "str1=\"vatican and teacher or start\"\n",
    "w=str1.split()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=-1\n",
    "result=None\n",
    "for s in w:\n",
    "    i=i+1\n",
    "    if s==\"and\" :\n",
    "        x=i-1;\n",
    "        y=i+1;\n",
    "        word1=inverted_index.get(w[x])\n",
    "        word2=inverted_index.get(w[y])\n",
    "        result=word1.intersection(word2)\n",
    "    elif s==\"and\" and i>2:\n",
    "        y=i+1\n",
    "        word=inverted_index.get(w[y])\n",
    "        result=result.intersection_update(word)\n",
    "    elif s==\"or\" and i<=2 :\n",
    "        x=i-1;\n",
    "        y=i+1;\n",
    "        word1=inverted_index.get(w[x])\n",
    "        word2=inverted_index.get(w[y])\n",
    "        result=word1.intersection(word2)\n",
    "    elif s==\"or\" and i>2:\n",
    "        y=i+1\n",
    "        word=inverted_index.get(w[y])\n",
    "        result=result.union(word)\n",
    "    elif s==\"not\" and i>2:\n",
    "        result=list_docs.difference(result)\n",
    "    elif s==\"not\":\n",
    "        word1=inverted_index.get(w[i])\n",
    "        result=list_docs.difference(result)\n",
    "    else:\n",
    "        continue\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
